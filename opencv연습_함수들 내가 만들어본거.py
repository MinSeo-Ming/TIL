# -*- coding: utf-8 -*-
"""2020_2_ImgProc_Midterm_backup_version2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PdSuOFiji488Ob1bVjJZctWGQmShUzTE

구글 주피터 노트북 사용을 위한 초기 작업을 작성하시오
"""

from google.colab import drive 
drive.mount('/gdrive')

"""### 다음의 이미지 경로는 변경할 수 없습니다. 
### 다른 이미지나 경로가 다를 경우, 채점 대상에서 제외. 

미리 공개된 이미지 또는 시험 문제에 포함된 이미지를 해당 폴더에 복사하여 사용할 것.
입력 이미지: Penguins.png, shape는 (768, 1024, 3)

"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /gdrive/MyDrive/ImageProcClass/Notebook-Week07/

image_path = '../Dongkeun-OpenCV-ImgData/Penguins.png' 
image_path1 = '../Dongkeun-OpenCV-ImgData/20MidtermProb1-Res.png'
image_path2 = '../Dongkeun-OpenCV-ImgData/20MidtermProb2-Res.png'
image_path3 = '../Dongkeun-OpenCV-ImgData/20MidtermProb3-Res.png'
image_path4 = '../Dongkeun-OpenCV-ImgData/20MidtermProb4-Res.png'
image_path5 = '../Dongkeun-OpenCV-ImgData/20MidtermProb5-Res.png'

import cv2
import numpy as np
import matplotlib.pyplot as plt

# matplot color display
def show_with_matplotlib(img, title):
    """Shows an image using matplotlib capabilities"""
    if img is None:
      print("show_with_matplotlib: Could not read the image.")
      return

    if img.shape[2] != 3:
      print()
      print("show_with_matplotlib: given image does not contains 3 channels")
      return

    # Convert BGR image to RGB:
    img_RGB = img[:, :, ::-1]

    # Show the image using matplotlib:
    plt.imshow(img_RGB)
    plt.title(title)
    plt.show()

# matplot grayscale display
def show_with_matplotlib_gray(img, title):
   if img is None:
      print("show_with_matplotlib_gray: Could not read the image.")
      return

   if img is None:
      print()
      print("show_with_matplotlib: given image has more than 2 dim")
      return
      
   plt.imshow(img, cmap="gray")
   plt.title(title)
   plt.show()

# image equivalence check
def test_same_image(img1, img2):
	if img1.shape != img2.shape:
		print("img1.shape = ", img1.shape, " and img2.shape = ", img2.shape, ' are different')

	difference = cv2.subtract(img1, img2)
	b, g, r = cv2.split(difference)
	if np.bitwise_xor(img1,img2).any():
		print("img1 and img2 are not identical")
	else:
		print("img1 and img2 are identical.O.K.")

"""문제의 전체적인 흐름은 다음과 같습니다. 
1. 텍스트가 포함된 이미지를 마스크로 사용.
2. 마스크에 포함된 텍스트 부분에 해당하는 원래 이미지에서 복사
3. 복사된 텍스트 부분 원래 이미지 부분의 밝기 변경
4. 밝기가 변경된 이미지를 원래 이미지 복사본에 단계별로 중첩. 결과적으로 밝기가 다른 텍스트 형태를 가지는 이미지가 원래 이미지를 배경으로 중첩되는 결과를 만듬.



위의 단계를 달성하기 위해, 필요한 사용자 함수를 지시에 따라 작성하고 테스크 결과를 출력하여야 하며, 각 함수 별 소문제에 부분점수 없음. 
### 함수 형태는 주어진 대로 사용
### 테스크 코드 변형하지 말고 사용

다음의 변수는 문제를 푸는 과정에 필요한 전역변수들입니다. 변수 **text_postfix** 이외의 변수값은 변경하지 말고 사용할 것. 

- loop_control: 반복문 조절값
- font_scale: 폰트 크기 
- font_thickness: 폰트 굴기
- beta_increase_init: 이미지 밝기 초기값
- beta_increase_delta: 이미지 밝기 증가값
- combined_res: 문제 최종 결과 이미지 
- white_color: 흰색값
- font = cv2.FONT_HERSHEY_SIMPLEX: 폰트 종류
- text_postfix = " Cute Penguins!! 12345" # 변경하지 말고 사용 
- x_coord: x 좌표값
- y_coord: y 좌표값
- pos_delta: 좌표 변경값
"""

org_img = cv2.imread(image_path)
# parameters
loop_control = 3 # modified
pos_delta = 20 # modified
font_scale = 2
font_thickness = 15
beta_increase_init = 50
beta_increase_delta = 10
combined_res = org_img.copy()
white_color = (255, 255, 255)
font = cv2.FONT_HERSHEY_SIMPLEX
text_postfix = " Cute Penguins!! 12345"
x_coord = 50
y_coord = 300

"""문제 1: 함수 make_text_mask 를 작성하고, 임의의 값을 이용하여 테스트 결과를 출력하시오. (5점)

make_text_mask 는 검은 색 바탕에 주어진 패러미터에 따라 텍스트를 포함하는 BGR 이미지를 반환

함수는 다음과 같이 정의된 바를 따름.

* def make_text_mask(img_height, img_width, ypos, xpos, text, font, fscale, font_color, thickness)
* img_height: 생성되는 이미지의 높이
* img_width: 생성되는 이미지의 넓이
* ypos: 텍스트가 출력되는 y 좌표값
* xpos: 텍스트가 출력되는 x 좌표값
* text: 출력되는 텍스트
* font: 출력되는 텍스트 폰트값
* fscale: 폰트 크기
* font_color: 폰트색
* thickness: 폰트 굵기


"""

# insert your code here
def make_text_mask(img_height, img_width, ypos, xpos, text, font, fscale, font_color, thickness):
  img = np.zeros((img_height,img_width,3),np.uint8)
  cv2.putText(img,text,(xpos,ypos),font,fscale,font_color,thickness)
  return img

# test problem1 
text_mask = make_text_mask(org_img.shape[0], org_img.shape[1], y_coord, x_coord, text_postfix, font, font_scale, white_color, font_thickness)
p1_ans = cv2.imread(image_path1, cv2.IMREAD_COLOR)
test_same_image(text_mask, p1_ans)
show_with_matplotlib(text_mask, "text mask")

"""문제 2: 함수 copyTextROI를 작성하고, 임의의 값을 이용하여 테스트 결과를 출력하시오. (15점)
- copyTextROI 는 입력 이미지 중 위에서 마스크 이미지의 텍스트 영역에 포함되는 부분 이미지를 포함하는 이미지 반환

함수는 다음과 같이 정의된 바를 따름.

* def copyTextROI(org_image, text_mask)
* org_image: 배경 이미지
* text_mask: 텍스트 이미지
"""

# insert your code
def copyTextROI(img,mask):
  result = cv2.bitwise_and(mask,img)
  return result

# test problem 2
roi_test_image = copyTextROI(org_img, text_mask)
p2_ans = cv2.imread(image_path2, cv2.IMREAD_COLOR)
test_same_image(roi_test_image, p2_ans)
show_with_matplotlib(roi_test_image, "text ROI")

"""문제 3: 함수 changeBrightnessForMask 를 작성하고, 임의의 값을 이용하여 테스트 결과를 출력하시오. (15점)

* changeBrightnessForMask 는 이미지의 특정 부분만의 화소값을 변경한 이미지를 반환

* 밝기와 콘트라스트를 동시에 콘트롤 할 수 있는 공식을 사용할 것.적절하게 사용하지 않은 경우 0점.

* np.clip을 사용할 것. 적절하게 사용하지 않은 경우 0점.

함수는 다음과 같이 정의된 바를 따름.

* def changeBrightnessForMask(image, mask, alpha, beta)

* image: 입력이미지

* mask: 매스크용 이미지

* alpha: 콘트라스트 조절값

* beta: 밝기 조정값
"""

# insert your code
def changeBrightnessForMask(img,mask,alpha,beta):
  dst = np.zeros((img.shape),np.uint8)
  for y in range(mask.shape[0]):
    for x in range(mask.shape[1]):
      for c in range(mask.shape[2]):
        if mask.item(y,x,c)!=0:
          dst[y,x,c] = np.clip(alpha * img[y,x,c]+beta,0,255)
  return dst

# test problem 3
test_image_with_b_change = changeBrightnessForMask(roi_test_image, text_mask, 1, beta_increase_init)
p3_ans = cv2.imread(image_path3, cv2.IMREAD_COLOR)
test_same_image(test_image_with_b_change, p3_ans)
show_with_matplotlib(test_image_with_b_change, "text ROI")

"""문제 4: 함수 combineTwoImage를 작성하고 임의의 값을 이용하여 테스트 결과를 출력하시오. (10점)

*combineTwoImage 는 두 개의 이미지를 합성한 이미지를 반환

* 이미지 합성 시, 바탕이 되는 이미지 위에 마스크 부분만을 중첩시킴. 따라서, 중복되는 영역은 바탕 이미지는 사라지고, 복사되는 이미지가 삽입됨

함수는 다음과 같이 정의된 바를 따름.

* def combineTwoImage(back_image, over_image)

* back_image: 백그라운드 이미지

* over_image: 위에 중첩되는 이미지
"""

# insert your code
def combineTwoImage(back_image, over_image):
  masks = cv2.threshold(over_image,10,255,cv2.THRESH_BINARY)[1]
  masks = cv2.split(masks)
  fore = cv2.bitwise_or(masks[0],masks[1])
  fore = cv2.bitwise_or(masks[2],fore)
  bg = cv2.bitwise_not(fore)
  foreg = cv2.bitwise_and(over_image,over_image,mask=fore)
  back = cv2.bitwise_and(back_image,back_image,mask=bg)
  result = cv2.bitwise_or(back, foreg)
  return result

# test problem 4
combined_image_test = combineTwoImage(org_img, test_image_with_b_change)
p4_ans = cv2.imread(image_path4, cv2.IMREAD_COLOR)
test_same_image(combined_image_test, p4_ans)
show_with_matplotlib(combined_image_test, "combined image test")

"""문제 5: 위에서 작성한 함수를 이용하여, 동일 텍스트가 출력되는 위치와 밝기를 바꾸어 중첩시키는 결과 이미지를 출력하시오. (5점)

* 최종 결과 이미지는 변수 combined_res 사용
* 첫번째 텍스트는 위에서 선언한 x_coord, y_coord를 초기값으로 사용
좌표 변경치는 pos_delta를 이용
* 밝기값은 위의 패러미터 중 beta_increase_init을 초기값으로 하고, 증가값을 beta_increase_delta 을 이용
* 반복문 한계는 위에서 선언한 loop_control 을 이용
* 나머지 폰트 관련값들은 위에서 선언한 값들을 이용
"""

# insert your code

for i in range(0,loop_control):
  text_mask = make_text_mask(org_img.shape[0], org_img.shape[1], y_coord, x_coord, text_postfix, font, font_scale, white_color, font_thickness)
  roi_test_image = copyTextROI(org_img, text_mask)
  test_image_with_b_change = changeBrightnessForMask(roi_test_image, text_mask, 1, beta_increase_init)
  combined_res =combineTwoImage(combined_res,test_image_with_b_change)

  x_coord = x_coord +pos_delta 
  y_coord = y_coord +pos_delta  
  beta_increase_init =beta_increase_init+beta_increase_delta

# test problem 5
p5_ans = cv2.imread(image_path5, cv2.IMREAD_COLOR)
test_same_image(combined_res, p5_ans)
show_with_matplotlib(combined_res, "final result")